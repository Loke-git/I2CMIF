{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "Checking requirements...\n",
      "\tRequirements met.\n",
      "Importing libraries...\n",
      "\n",
      "Getting metadata from config.ini...\n",
      "Index: Letters to and from Henrik Ibsen 1844-1905\n",
      "UID: ls582794c-7ba2-11ed-a1eb-0242ac120002\n",
      "Editor: Nina Marie Evensen (n.m.evensen@ibsen.uio.no) at Senter for Ibsen-studier (https://www.ibsen.uio.no/)\n",
      "ibsen.uio.no. Digitalt arkiv over Henrik Ibsens brev publisert av Senter for Ibsen-studier.\n",
      "Output: ibsen-korrespondanse_HT.xml (main texts only) and ibsen-korrespondanse_HTV.xml (main texts and varia)\n",
      "Targeting these files: letters\\B1844-1871ht.xml, letters\\B1871-1879ht.xml, letters\\B1880-1889ht.xml, letters\\B1890-1905ht.xml\n",
      "Melting letters\\B1844-1871ht.xml\n",
      "Melting letters\\B1871-1879ht.xml\n",
      "Melting letters\\B1880-1889ht.xml\n",
      "Melting letters\\B1890-1905ht.xml\n",
      "Acquired GeoNames IDs for these places:\n",
      "['GRIMSTAD', 'KRISTIANIA', 'KØBENHAVN', 'DRESDEN', 'BERGEN', 'TRONDHEIM', 'ROMA', 'ARICCIA', 'FRASCATI', 'ISCHIA', 'SORRENTO', 'SAN GERMANO', 'BERCHTESGADEN', 'MÜNCHEN', 'STOCKHOLM', 'BERCHTESGADEN, BAYERN', 'WIEN', 'PILLNITZ VED DRESDEN', 'KITZBÜCHEL, TYROL', 'KALTERN', 'UPPSALA', 'GOSSENSASS', 'AMALFI', 'TYROL', 'BOZEN', 'MOLDE', 'MEININGEN', 'SÆBY', 'FREDRIKSHAVN', 'GÖTEBORG', 'VÄNERSBORG', 'BERLIN', 'WEIMAR', 'BUDAPEST', 'SANDEFJORD', 'HAMMERFEST']\n",
      "Checking for varia_file.csv...\n",
      "Processing varia...\n",
      "\n",
      ">> Warning: the CMIF will use links valid in 2022, meaning that the correct global person/institution ID (e.g. orgSF) is referred to as the old varia-specific ID (e.g. Skand) in the document IDs. Modify the source CSV with new links if applicable, or change them after the fact in the CMIF.\n",
      "\thttps://www.ibsen.uio.no/VAR_V1858kongO2.xhtml (https://www.ibsen.uio.no/REGINFO_peKongO2.xhtml)\n",
      "\thttps://www.ibsen.uio.no/VAR_V1860Skand.xhtml (https://www.ibsen.uio.no/REGINFO_orgSF.xhtml)\n",
      "\thttps://www.ibsen.uio.no/VAR_V1861Skand.xhtml (https://www.ibsen.uio.no/REGINFO_orgSF.xhtml)\n",
      "\thttps://www.ibsen.uio.no/VAR_V18690926HSTp.xhtml (https://www.ibsen.uio.no/REGINFO_peHSto.xhtml)\n",
      "\thttps://www.ibsen.uio.no/VAR_V18901219HeG.xhtml (https://www.ibsen.uio.no/REGINFO_peHGr.xhtml)\n",
      "\thttps://www.ibsen.uio.no/VAR_V18930718EPh.xhtml (https://www.ibsen.uio.no/REGINFO_peEdBr.xhtml)\n",
      "This warning will cease once the script does not detect the above links.\n",
      "\n",
      "Acquired 102 items from varia.\n",
      "Remember! These links will only work as long as they're in the ibsen.uio.no/VAR_ domain.\n",
      "\n",
      "Creating standard CMIF...\n",
      "Saving output...\n",
      "Done exporting CMIF as ibsen-korrespondanse_HT\n",
      "Saved metadata in ibsen-correspondence-metadata_ht.json\n",
      "\n",
      "These documents have strange placenames:\n",
      "['B18580604CHo', 'Budat1884Stort', 'Budat18880514FinDep', 'Budat189110NN_Opfordring']\n",
      "['DAMPSKIPET CHRISTIANIA', 'KRISTIANIAROMA', 'KRISTIANIAMÜNCHEN', 'KRISTIANIABERGEN']\n",
      "\n",
      "\n",
      "Creating varia-augmented CMIF...\n",
      "Saving output...\n",
      "Done exporting CMIF as ibsen-korrespondanse_HTV\n",
      "Saved metadata in ibsen-correspondence-metadata_htv.json\n",
      "\n",
      "These documents have strange placenames:\n",
      "['B18580604CHo', 'Budat1884Stort', 'Budat18880514FinDep', 'Budat189110NN_Opfordring']\n",
      "['DAMPSKIPET CHRISTIANIA', 'KRISTIANIAROMA', 'KRISTIANIAMÜNCHEN', 'KRISTIANIABERGEN']\n",
      "All done! Have a nice day.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "print(\"Initializing...\")\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "print(\"Checking requirements...\")\n",
    "# Package installation borrowed from:\n",
    "# https://stackoverflow.com/questions/12332975/installing-python-module-within-code/58040520#58040520\n",
    "required  = {'bs4', 'pandas'} \n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing   = required - installed\n",
    "if missing:\n",
    "    # implement pip as a subprocess:\n",
    "    print(\"\\tInstalling requirements...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])\n",
    "else:\n",
    "    print(\"\\tRequirements met.\")\n",
    "\n",
    "# Ibsen XML Muncher 1\n",
    "# Much of this code has been appropriated from the Munch XML Muncher (MXMLM) tool.\n",
    "    \n",
    "print(\"Importing libraries...\")\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# File and folder handling\n",
    "import glob # The yeast of thought and mind\n",
    "import os # File system\n",
    "\n",
    "# Metadata and configuration\n",
    "import configparser # Used to easily get statements from the config file\n",
    "\n",
    "# Time and date\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "today = today.strftime(\"%Y-%m-%d\") # Formater dato\n",
    "\n",
    "df = pd.read_csv(\"Compiled_Letter_Data.csv\", sep=\",\")\n",
    "df = df[['Dispatch_Location',\"GeoName_ID\"]].fillna(\"N/A\")\n",
    "placeIDdict = defaultdict(dict)\n",
    "places = []\n",
    "for idx,row in df.iterrows():\n",
    "    place = str(row['Dispatch_Location'])\n",
    "    place = place.lstrip('[').rstrip(\"]\").upper()\n",
    "    if place not in places:\n",
    "        if str(row['GeoName_ID']) != \"N/A\":\n",
    "            places.append(place)\n",
    "            placeid = str(row['GeoName_ID']).split(\".\")\n",
    "            placeid = placeid[0]\n",
    "            placeIDdict[place] = placeid\n",
    "\n",
    "            \n",
    "print(\"\\nGetting metadata from config.ini...\")\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\", encoding=\"utf-8\")\n",
    "cmifTitle = config.get(\"statements\", \"cmifTitle\")\n",
    "editorName = config.get(\"statements\", \"editorName\")\n",
    "editorMail = config.get(\"statements\", \"editorMail\")\n",
    "cmifUid = config.get(\"statements\", \"cmifUid\")\n",
    "publisherURL = config.get(\"statements\", \"publisherURL\")\n",
    "publisherName = config.get(\"statements\", \"publisherName\")\n",
    "cmifURL = config.get(\"statements\", \"cmifURL\")\n",
    "typeOfBibl = config.get(\"statements\", \"typeOfBibl\")\n",
    "publicationStatementFull = config.get(\"statements\", \"publicationStatementFull\")\n",
    "outputFileName = config.get(\"statements\", \"outputFileName\")\n",
    "outputFileNameVaria = config.get(\"statements\", \"outputFileNameVaria\")\n",
    "\n",
    "print(f\"{cmifTitle}\\nUID: {cmifUid}\\nEditor: {editorName} ({editorMail}) at {publisherName} ({publisherURL})\\n{publicationStatementFull}\\nOutput: {outputFileName}.xml (main texts only) and {outputFileNameVaria}.xml (main texts and varia)\")\n",
    "t = \"Targeting these files: \"\n",
    "listXMLfiles = glob.glob(\"letters/*.xml\",recursive=True)\n",
    "i=0\n",
    "for file in listXMLfiles:\n",
    "    if i!= 0:\n",
    "        t += \", \"\n",
    "    t+=str(file)\n",
    "    i+=1\n",
    "print(t)\n",
    "main = defaultdict(dict)\n",
    "\n",
    "i=0\n",
    "\n",
    "for xml_file in listXMLfiles:\n",
    "    pathSplit = xml_file.split(\"\\\\\")\n",
    "    fileName = pathSplit[1]\n",
    "    fileName = fileName.split(\".\")\n",
    "    fileName = str(fileName[0])\n",
    "    fileName = \"https://www.ibsen.uio.no/BREV_\"+fileName[1:]\n",
    "    print(\"Melting\",xml_file)\n",
    "    with open(xml_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = file.readlines()\n",
    "        # Combine the lines in the list into a string\n",
    "        content = \"\".join(content)\n",
    "        soup = bs(content, \"xml\")\n",
    "    for document in soup.findAll('HIS:hisMsDesc', {\"xml:id\":True}):\n",
    "        theAuthorsRefs,theAuthors,theAuthorsTypes,theRecipients,theRecipientsRefs,theRecipientsTypes = [],[],[],[],[],[]\n",
    "        docType = list(document.attrs.values())[0]\n",
    "        docID = list(document.attrs.values())[1]\n",
    "        printString = str(docID)\n",
    "        \n",
    "        try:\n",
    "            docLoc = document.find(\"origPlace\").findChild(\"HIS:hisRef\", {\"type\":\"place\"}).contents[0]\n",
    "            place = document.find(\"origPlace\").findChild(\"HIS:hisRef\", {\"type\":\"place\"})\n",
    "            placeID = list(place.attrs.values())[1]\n",
    "            placeID = placeID.replace(\"Navneregister_HISe.xml#\",\"\")\n",
    "\n",
    "        except:\n",
    "            docLoc = \"UKJENT OPPRINNELSESSTED\"\n",
    "            placeID = \"plNN\"\n",
    "        printString+=\", \"+docType+\" from \"+docLoc\n",
    "        \n",
    "        \n",
    "        dateObj = document.find(\"origDate\")\n",
    "\n",
    "        date = list(dateObj.attrs.values())[0]\n",
    "        printString+=\" dated: \"+date\n",
    "        printString+=\"\\n\"\n",
    "        senders = document.find(\"name\",{\"role\":\"sender\"}).findChildren(True, recursive=True)\n",
    "        printString+=\"Senders: \"\n",
    "        for sender in senders:\n",
    "            senderType = list(sender.attrs.values())[0]\n",
    "            senderRef = list(sender.attrs.values())[1]\n",
    "            senderRef = senderRef.replace(\"Navneregister_HISe.xml#\",\"\")\n",
    "            for senderName in sender.contents:\n",
    "                printString+=senderName+\" (\"+senderType+\")\"\n",
    "                theAuthors.append(senderName)\n",
    "                theAuthorsTypes.append(senderType)\n",
    "                theAuthorsRefs.append(senderRef)\n",
    "        recips = document.find(\"name\",{\"role\":\"recipient\"}).findChildren(True, recursive=True)\n",
    "        printString+=\" | Recipients: \"\n",
    "        for recip in recips:\n",
    "            recipType = list(recip.attrs.values())[0]\n",
    "            recipRef = list(recip.attrs.values())[1]\n",
    "            recipRef = recipRef.replace(\"Navneregister_HISe.xml#\",\"\")\n",
    "            for recipName in recip.contents:\n",
    "                printString+=recipName+\" (\"+recipType+\")\"\n",
    "                theRecipients.append(recipName)\n",
    "                theRecipientsTypes.append(recipType)\n",
    "                theRecipientsRefs.append(recipRef)\n",
    "                \n",
    "        docLoc = docLoc.lstrip('[').rstrip(\"]\").upper()\n",
    "        \n",
    "        if docLoc in placeIDdict:\n",
    "            placeID = placeIDdict[docLoc]\n",
    "        else:\n",
    "            placeID = \"N/A\"\n",
    "        main[docID]['type'] = docType\n",
    "        main[docID]['date'] = date\n",
    "        main[docID]['from'] = theAuthors\n",
    "        main[docID]['fromRef'] = theAuthorsRefs\n",
    "        main[docID]['fromType'] = theAuthorsTypes\n",
    "        main[docID]['to'] = theRecipients\n",
    "        main[docID]['toRef'] = theRecipientsRefs\n",
    "        main[docID]['toType'] = theRecipientsTypes\n",
    "        main[docID]['place'] = docLoc\n",
    "        main[docID]['placeRef'] = placeID\n",
    "        main[docID]['source'] = fileName+\"|\"+docID+\".xhtml\"\n",
    "\n",
    "        i+=1\n",
    "print(\"Acquired GeoNames IDs for these places:\")\n",
    "print(list(placeIDdict.keys()))\n",
    "df1 = pd.DataFrame.from_dict(main).T.reset_index(drop=False)\n",
    "df1.columns = \"document\",\"type\",\"date\",\"fromX\",\"fromRef\",\"fromType\",\"to\",\"toRef\",\"toType\",\"place\",\"placeRef\",\"source\"\n",
    "\n",
    "# Varia (miscellany) metadata harvesting \n",
    "print(\"Checking for varia_file.csv...\")\n",
    "if os.path.exists(\"varia_file.csv\"):\n",
    "    print(\"Processing varia...\")\n",
    "    old_links = [\"https://www.ibsen.uio.no/VAR_V18901219HeG.xhtml\",\"https://www.ibsen.uio.no/VAR_V1858kongO2.xhtml\",\"https://www.ibsen.uio.no/VAR_V18930718EPh.xhtml\",\"https://www.ibsen.uio.no/VAR_V18690926HSTp.xhtml\",\"https://www.ibsen.uio.no/VAR_V1860Skand.xhtml\",\"https://www.ibsen.uio.no/VAR_V1861Skand.xhtml\",\"https://www.ibsen.uio.no/VAR_1862Skand.xhtml\"]\n",
    "    i=0\n",
    "    warned_about_old_links = False\n",
    "    supplement = defaultdict(dict)\n",
    "    varia = pd.read_csv(\"varia_file.csv\",sep=\",\").set_index(\"index\")\n",
    "    varia = varia.fillna(\"N/A\")\n",
    "    for idx,row in varia.iterrows():\n",
    "        recipientID = row['fullID']\n",
    "        if recipientID != \"N/A\":\n",
    "            i+=1\n",
    "            title,date,recipient,docType = row['title'],row['date'],row['clearname'],row['type']\n",
    "            link = \"https://www.ibsen.uio.no/VAR_\"+str(idx)+\".xhtml\"\n",
    "            recipRef = \"https://www.ibsen.uio.no/REGINFO_\"+str(recipientID)+\".xhtml\"\n",
    "            if \"pe\" in recipientID:\n",
    "                recipType = \"person\"\n",
    "            elif \"org\" in recipientID:\n",
    "                recipType = \"org\"\n",
    "            #print(f\"{idx}\\n\\t{title} from Ibsen to {recipient}, dated {date}\\n\\t{recipRef}\\n\\t{link}\")\n",
    "            supplement[idx]['type'] = docType\n",
    "            supplement[idx]['date'] = date\n",
    "            supplement[idx]['from'] = [\"HENRIK IBSEN\"]\n",
    "            supplement[idx]['fromRef'] = [\"peHI\"]\n",
    "            supplement[idx]['fromType'] = [\"person\"]\n",
    "            supplement[idx]['to'] = [recipient]\n",
    "            supplement[idx]['toRef'] = [recipientID]\n",
    "            supplement[idx]['toType'] = [recipType]\n",
    "            supplement[idx]['place'] = \"N/A\"\n",
    "            supplement[idx]['placeRef'] = \"N/A\"\n",
    "            supplement[idx]['source'] = link\n",
    "            if link in old_links:\n",
    "                if warned_about_old_links == False:\n",
    "                    print(\"\\n>> Warning: the CMIF will use links valid in 2022, meaning that the correct global person/institution ID (e.g. orgSF) is referred to as the old varia-specific ID (e.g. Skand) in the document IDs. Modify the source CSV with new links if applicable, or change them after the fact in the CMIF.\")\n",
    "                    warned_about_old_links = True\n",
    "                print(\"\\t\"+link+\" (\"+recipRef+\")\")\n",
    "    if warned_about_old_links == True:\n",
    "        print(\"This warning will cease once the script does not detect the above links.\")\n",
    "    print(f\"\\nAcquired {i} items from varia.\\nRemember! These links will only work as long as they're in the ibsen.uio.no/VAR_ domain.\\n\")\n",
    "    df2 = pd.DataFrame.from_dict(supplement).T.reset_index(drop=False).fillna(\"N/A\")\n",
    "    df2.columns = \"document\",\"type\",\"date\",\"fromX\",\"fromRef\",\"fromType\",\"to\",\"toRef\",\"toType\",\"place\",\"placeRef\",\"source\"\n",
    "    df3 = df1.append(df2, ignore_index=True).reset_index(drop=True)\n",
    "    df4 = df3.copy().set_index(\"document\")\n",
    "    df4_json = df4.to_json(orient=\"index\")\n",
    "# End varia metadata harvesting\n",
    "\n",
    "# Standard CMIF (all normal letter correspondence)\n",
    "# Append to UID..\n",
    "cmifUid = cmifUid + \"HT\"\n",
    "# Catch documents with weird/combined placenames in these\n",
    "letters_with_weird_placenames,weird_placenames_in_letters = [],[]\n",
    "print(\"Creating standard CMIF...\")\n",
    "# Create CMIF boilerplate object\n",
    "CMIFstring = '<?xml-model href=\"https://raw.githubusercontent.com/TEI-Correspondence-SIG/CMIF/master/schema/cmi-customization.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?><TEI xmlns=\"http://www.tei-c.org/ns/1.0\"><teiHeader><fileDesc><titleStmt><title>'+str(cmifTitle)+'</title><editor>'+str(editorName)+'<email>'+str(editorMail)+'</email></editor></titleStmt><publicationStmt><publisher><ref target=\"'+str(publisherURL)+'\">'+str(publisherName)+'</ref></publisher><idno type=\"url\">'+str(cmifURL)+'</idno><date when=\"'+str(today)+'\"/><availability><licence target=\"https://creativecommons.org/licenses/by/4.0/\">This file is licensed under the terms of the Creative-Commons-License CC-BY 4.0</licence></availability></publicationStmt><sourceDesc><bibl type=\"'+str(typeOfBibl)+'\" xml:id=\"'+str(cmifUid)+'\">'+str(publicationStatementFull)+'</bibl></sourceDesc></fileDesc><profileDesc><dummy/></profileDesc></teiheader><text><body><p/></body></text></tei>'\n",
    "CMIF = bs(CMIFstring,\"xml\") # Read as XML, not HTML\n",
    "profileDescElement = CMIF.find('profileDesc') # Target correspondence wrapper\n",
    "for idx,row in df1.iterrows():\n",
    "    document,date,fromX,to,place,placeRef,source = row['document'],row['date'],row['fromX'],row['to'],row['place'],row['placeRef'],row['source']\n",
    "    \n",
    "    # Construct CMIF correspDesc element\n",
    "    correspDescElement = CMIF.new_tag(\"correspDesc\", attrs={\"key\":str(document), \"ref\":source, \"source\":\"#\"+cmifUid})\n",
    "    profileDescElement.append(correspDescElement)\n",
    "    i=0\n",
    "    ## Author (sender) encoding\n",
    "    \n",
    "    for each in fromX:\n",
    "        # For each author, add a correspAction element...\n",
    "        correspActionElement = CMIF.new_tag(\"correspAction\", attrs={'type':'sent'})\n",
    "        correspDescElement.append(correspActionElement)\n",
    "        category = df1.iloc[idx][\"fromType\"][i]\n",
    "        ref = str(\"https://www.ibsen.uio.no/REGINFO_\")+str(df1.iloc[idx][\"fromRef\"][i])+str(\".xhtml\")\n",
    "        if category == \"org\":\n",
    "            if ref != \"N/A\":\n",
    "                persNameElement = CMIF.new_tag(\"orgName\", attrs={\"ref\":ref})\n",
    "            else:\n",
    "                persNameElement = CMIF.new_tag(\"orgName\")\n",
    "        else:\n",
    "            if ref != \"N/A\":\n",
    "                persNameElement = CMIF.new_tag(\"persName\", attrs={\"ref\":ref})\n",
    "            else:\n",
    "                persNameElement = CMIF.new_tag(\"persName\")\n",
    "        persNameElement.string = str(each)\n",
    "        correspActionElement.append(persNameElement)\n",
    "        i+=1\n",
    "    # Place encoding\n",
    "    if place != \"N/A\" and place != \"UKJENT OPPRINNELSESSTED\":\n",
    "        if placeRef != \"N/A\" and placeRef != \"plNN\":\n",
    "            locationElement = CMIF.new_tag(\"placeName\", attrs={\"ref\":\"http://www.geonames.org/\"+placeRef}) # Create place element\n",
    "        else:\n",
    "            locationElement = CMIF.new_tag(\"placeName\")#, attrs={\"ref\":placeRef} # Create place element\n",
    "            letters_with_weird_placenames.append(document)\n",
    "            weird_placenames_in_letters.append(place)\n",
    "        locationElement.string = str(place) # Give it a string value (placename)\n",
    "        correspActionElement.append(locationElement) # Append the new element to the correspAction element\n",
    "    # End place encoding\n",
    "    # Date encoding\n",
    "    if date != \"N/A\":\n",
    "        dateSentElement = CMIF.new_tag(\"date\", attrs={\"when\":date})\n",
    "        correspActionElement.append(dateSentElement)\n",
    "    # End date encoding\n",
    "    # End author (sender) encoding\n",
    "    \n",
    "    i=0\n",
    "    # Recipient encoding\n",
    "    for each in to:\n",
    "        correspActionElement = CMIF.new_tag(\"correspAction\", attrs={'type':'received'})\n",
    "        correspDescElement.append(correspActionElement)\n",
    "        category = df1.iloc[idx][\"toType\"][i]\n",
    "        ref = str(\"https://www.ibsen.uio.no/REGINFO_\")+str(df1.iloc[idx][\"toRef\"][i])+str(\".xhtml\")\n",
    "        #ref = df1.iloc[idx][\"toRef\"][i]\n",
    "        if each == \"UKJENT MOTTAGER\":\n",
    "            each = \"UNKNOWN RECIPIENT\"\n",
    "        if category == \"org\":\n",
    "            if ref != \"N/A\":\n",
    "                persNameElement = CMIF.new_tag(\"orgName\", attrs={\"ref\":ref})\n",
    "            else:\n",
    "                persNameElement = CMIF.new_tag(\"orgName\")\n",
    "        else:\n",
    "            if ref != \"N/A\":\n",
    "                persNameElement = CMIF.new_tag(\"persName\", attrs={\"ref\":ref})\n",
    "            else:\n",
    "                persNameElement = CMIF.new_tag(\"persName\")\n",
    "        i+=1\n",
    "        persNameElement.string = str(each)\n",
    "        correspActionElement.append(persNameElement)\n",
    "\n",
    "    # End recipient encoding\n",
    "\n",
    "dummyElement = CMIF.find(\"dummy\").decompose() # This will destroy the <dummy/> element.\n",
    "\n",
    "print(\"Saving output...\")\n",
    "CMIFstr = str(CMIF)\n",
    "CMIF = bs(CMIFstr, \"xml\", preserve_whitespace_tags=[\"placeName\",\"bibl\",\"corresp\",\"title\",\"persName\",\"editor\",\"email\",\"publisher\",\"ref\",\"idno\",\"licence\"])\n",
    "with open(outputFileName+\".xml\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(CMIF.prettify())\n",
    "\n",
    "print(\"Done exporting CMIF as\",outputFileName)\n",
    "with open(\"ibsen-correspondence-metadata_ht.json\", \"w\") as outfile:\n",
    "    json.dump(main, outfile, indent = 4)\n",
    "print(\"Saved metadata in ibsen-correspondence-metadata_ht.json\")\n",
    "\n",
    "if len(weird_placenames_in_letters) > 0:\n",
    "    print(f\"\\nThese documents have strange placenames:\\n{letters_with_weird_placenames}\\n{weird_placenames_in_letters}\")\n",
    "    \n",
    "# End standard CMIF\n",
    "\n",
    "\n",
    "if os.path.exists(\"varia_file.csv\"):\n",
    "    # Experimental standard + varia CMIF\n",
    "\n",
    "    # Catch documents with weird/combined placenames in these\n",
    "    letters_with_weird_placenames,weird_placenames_in_letters = [],[]\n",
    "    print(\"\\n\\nCreating varia-augmented CMIF...\")\n",
    "    # Change the UID..\n",
    "    cmifUid = cmifUid + \"V\"\n",
    "    # Create CMIF boilerplate object\n",
    "    CMIFstring = '<?xml-model href=\"https://raw.githubusercontent.com/TEI-Correspondence-SIG/CMIF/master/schema/cmi-customization.rng\" type=\"application/xml\" schematypens=\"http://relaxng.org/ns/structure/1.0\"?><TEI xmlns=\"http://www.tei-c.org/ns/1.0\"><teiHeader><fileDesc><titleStmt><title>'+str(cmifTitle)+'</title><editor>'+str(editorName)+'<email>'+str(editorMail)+'</email></editor></titleStmt><publicationStmt><publisher><ref target=\"'+str(publisherURL)+'\">'+str(publisherName)+'</ref></publisher><idno type=\"url\">'+str(cmifURL)+'</idno><date when=\"'+str(today)+'\"/><availability><licence target=\"https://creativecommons.org/licenses/by/4.0/\">This file is licensed under the terms of the Creative-Commons-License CC-BY 4.0</licence></availability></publicationStmt><sourceDesc><bibl type=\"'+str(typeOfBibl)+'\" xml:id=\"'+str(cmifUid)+'\">'+str(publicationStatementFull)+'</bibl></sourceDesc></fileDesc><profileDesc><dummy/></profileDesc></teiheader><text><body><p/></body></text></tei>'\n",
    "    CMIF = bs(CMIFstring,\"xml\") # Read as XML, not HTML\n",
    "    profileDescElement = CMIF.find('profileDesc') # Target correspondence wrapper\n",
    "    for idx,row in df3.iterrows():\n",
    "        document,date,fromX,to,place,placeRef,source = row['document'],row['date'],row['fromX'],row['to'],row['place'],row['placeRef'],row['source']\n",
    "\n",
    "        # Construct CMIF correspDesc element\n",
    "        correspDescElement = CMIF.new_tag(\"correspDesc\", attrs={\"key\":str(document), \"ref\":source, \"source\":\"#\"+cmifUid})\n",
    "        profileDescElement.append(correspDescElement)\n",
    "        i=0\n",
    "        ## Author (sender) encoding\n",
    "\n",
    "        for each in fromX:\n",
    "            # For each author, add a correspAction element...\n",
    "            correspActionElement = CMIF.new_tag(\"correspAction\", attrs={'type':'sent'})\n",
    "            correspDescElement.append(correspActionElement)\n",
    "            category = df3.iloc[idx][\"fromType\"][i]\n",
    "            ref = str(\"https://www.ibsen.uio.no/REGINFO_\")+str(df3.iloc[idx][\"fromRef\"][i])+str(\".xhtml\")\n",
    "            if category == \"org\":\n",
    "                if ref != \"N/A\":\n",
    "                    persNameElement = CMIF.new_tag(\"orgName\", attrs={\"ref\":ref})\n",
    "                else:\n",
    "                    persNameElement = CMIF.new_tag(\"orgName\")\n",
    "            else:\n",
    "                if ref != \"N/A\":\n",
    "                    persNameElement = CMIF.new_tag(\"persName\", attrs={\"ref\":ref})\n",
    "                else:\n",
    "                    persNameElement = CMIF.new_tag(\"persName\")\n",
    "            persNameElement.string = str(each)\n",
    "            correspActionElement.append(persNameElement)\n",
    "            i+=1\n",
    "        # Place encoding\n",
    "        if place != \"N/A\" and place != \"UKJENT OPPRINNELSESSTED\":\n",
    "            if placeRef != \"N/A\" and placeRef != \"plNN\":\n",
    "                locationElement = CMIF.new_tag(\"placeName\", attrs={\"ref\":\"http://www.geonames.org/\"+placeRef}) # Create place element\n",
    "            else:\n",
    "                locationElement = CMIF.new_tag(\"placeName\")#, attrs={\"ref\":placeRef} # Create place element\n",
    "                letters_with_weird_placenames.append(document)\n",
    "                weird_placenames_in_letters.append(place)\n",
    "            locationElement.string = str(place) # Give it a string value (placename)\n",
    "            correspActionElement.append(locationElement) # Append the new element to the correspAction element\n",
    "        # End place encoding\n",
    "        # Date encoding\n",
    "        if date != \"N/A\":\n",
    "            dateSentElement = CMIF.new_tag(\"date\", attrs={\"when\":date})\n",
    "            correspActionElement.append(dateSentElement)\n",
    "        # End date encoding\n",
    "        # End author (sender) encoding\n",
    "\n",
    "        i=0\n",
    "        # Recipient encoding\n",
    "        for each in to:\n",
    "            correspActionElement = CMIF.new_tag(\"correspAction\", attrs={'type':'received'})\n",
    "            correspDescElement.append(correspActionElement)\n",
    "            category = df3.iloc[idx][\"toType\"][i]\n",
    "            ref = str(\"https://www.ibsen.uio.no/REGINFO_\")+str(df3.iloc[idx][\"toRef\"][i])+str(\".xhtml\")\n",
    "            #ref = df3.iloc[idx][\"toRef\"][i]\n",
    "            if each == \"UKJENT MOTTAGER\":\n",
    "                each = \"UNKNOWN RECIPIENT\"\n",
    "            if category == \"org\":\n",
    "                if ref != \"N/A\":\n",
    "                    persNameElement = CMIF.new_tag(\"orgName\", attrs={\"ref\":ref})\n",
    "                else:\n",
    "                    persNameElement = CMIF.new_tag(\"orgName\")\n",
    "            else:\n",
    "                if ref != \"N/A\":\n",
    "                    persNameElement = CMIF.new_tag(\"persName\", attrs={\"ref\":ref})\n",
    "                else:\n",
    "                    persNameElement = CMIF.new_tag(\"persName\")\n",
    "            i+=1\n",
    "            persNameElement.string = str(each)\n",
    "            correspActionElement.append(persNameElement)\n",
    "\n",
    "        # End recipient encoding\n",
    "\n",
    "    dummyElement = CMIF.find(\"dummy\").decompose() # This will destroy the <dummy/> element.\n",
    "\n",
    "    print(\"Saving output...\")\n",
    "    CMIFstr = str(CMIF)\n",
    "    CMIF = bs(CMIFstr, \"xml\", preserve_whitespace_tags=[\"placeName\",\"bibl\",\"corresp\",\"title\",\"persName\",\"editor\",\"email\",\"publisher\",\"ref\",\"idno\",\"licence\"])\n",
    "    with open(outputFileNameVaria+\".xml\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(CMIF.prettify())\n",
    "\n",
    "    print(\"Done exporting CMIF as\",outputFileNameVaria)\n",
    "\n",
    "\n",
    "    parse_json = json.loads(df4_json)\n",
    "    with open(\"ibsen-correspondence-metadata_htv.json\", \"w\") as outfile:\n",
    "        json.dump(parse_json, outfile, indent = 4)\n",
    "    print(\"Saved metadata in ibsen-correspondence-metadata_htv.json\")\n",
    "\n",
    "    if len(weird_placenames_in_letters) > 0:\n",
    "        print(f\"\\nThese documents have strange placenames:\\n{letters_with_weird_placenames}\\n{weird_placenames_in_letters}\")\n",
    "\n",
    "    # End experimental CMIF\n",
    "\n",
    "print(\"All done! Have a nice day.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
